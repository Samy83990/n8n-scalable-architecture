# Guide de Test de ScalabilitÃ© n8n

## ğŸš€ DÃ©marrage Rapide

### Option 1: Test Automatique

```bash
./test-scalability.sh
```

## ğŸ“‹ PrÃ©requis

- Kubernetes cluster (local ou cloud)
- kubectl configurÃ©
- Docker installÃ©

## ğŸ¯ Objectifs des Tests

Valider que l'architecture n8n est capable de :

1. âœ… **Distribuer la charge** entre plusieurs workers
2. âœ… **RÃ©sister aux pannes** (auto-rÃ©cupÃ©ration)  
3. âœ… **Monter en charge** horizontalement
4. âœ… **Maintenir les performances** sous charge

### 1. DÃ©ploiement Initial

```bash
kubectl apply -k k8s/overlays/dev/
kubectl get pods -n n8n-dev

```**Screenshot**: Terminal montrant tous les pods `Running`

### 2. Interface n8n
```bash
kubectl port-forward -n n8n-dev svc/dev-n8n-api 8080:80

```**Screenshot**: Interface n8n sur http://localhost:8080

### 3. Workflows de Test
CrÃ©er dans l'interface n8n :
- Workflow 1: Schedule (15s) + HTTP Request  
- Workflow 2: Schedule (20s) + Data Processing
- Workflow 3: Schedule (30s) + API Calls

**Screenshot**: Liste des workflows actifs

### 4. Distribution de Charge
```bash
kubectl logs -n n8n-dev -l app=n8n-worker -f --prefix=true
```

### 5. Test de RÃ©silience

```bash
# Supprimer un worker
kubectl delete pod -n n8n-dev $(kubectl get pods -n n8n-dev -l app=n8n-worker -o name | head -1)

# Observer la rÃ©cupÃ©ration
kubectl get pods -n n8n-dev -w

```**Screenshot**: Avant/aprÃ¨s suppression d'un pod

### 6. MontÃ©e en Charge

```bash
kubectl scale deployment dev-n8n-worker --replicas=5 -n n8n-dev
kubectl get pods -n n8n-dev

```**Screenshot**: Passage de 2 Ã  5 workers

### 7. MÃ©triques de Performance

```bash
kubectl top pods -n n8n-dev ```
**Screenshot**: Utilisation CPU/RAM des pods

### 8. Validation Finale

Interface n8n â†’ Executions

**Screenshot**: Historique des exÃ©cutions rÃ©ussies

## ğŸ”§ Commandes Utiles

```bash
# Ã‰tat des pods
kubectl get pods -n n8n-dev -o wide

# Logs en temps rÃ©el
kubectl logs -n n8n-dev -l app=n8n-worker -f

# MÃ©triques
kubectl top pods -n n8n-dev

# Scaling
kubectl scale deployment dev-n8n-worker --replicas=X -n n8n-dev

# Nettoyage
kubectl delete namespace n8n-dev
```

## ğŸ¯ CritÃ¨res de Validation

### âœ… Test RÃ©ussi Si

- Tous les pods passent Ã  `Running`
- API rÃ©pond sur `/healthz` (200 OK)
- Workflows s'exÃ©cutent en parallÃ¨le
- Suppression d'un worker â†’ auto-rÃ©cupÃ©ration
- Scaling horizontal fonctionne
- Aucune perte de donnÃ©es

### âŒ Test Ã‰chouÃ© Si

- Pods en `CrashLoopBackOff`
- API inaccessible
- Workflows ne s'exÃ©cutent pas
- Pas de rÃ©cupÃ©ration aprÃ¨s panne
- Performance dÃ©gradÃ©e avec plus de workers

## ğŸ› Troubleshooting

### Pods qui ne dÃ©marrent pas

```bash
kubectl describe pod -n n8n-dev <pod-name>
kubectl logs -n n8n-dev <pod-name>
```

### Secrets manquants

```bash
source create-secrets.sh
create_secrets "n8n-dev" "dev-"
```

### Port-forward qui ne fonctionne pas

```bash
kubectl get svc -n n8n-dev
kubectl port-forward -n n8n-dev svc/dev-n8n-api 8080:80
```
